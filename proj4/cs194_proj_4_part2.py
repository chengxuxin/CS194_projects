# -*- coding: utf-8 -*-
"""cs194 proj 4 part2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LrMGVyqsyb4QtH7Z9dPyoP-N7ZJXU-q0
"""

!pip install -r requirements.txt

!nvidia-smi

! unzip starter_set.zip

import numpy as np
import os
import png
import torch
from tqdm import tqdm
from torch.utils.data.dataset import Dataset
from PIL import Image

class FacadeDataset(Dataset):
    def __init__(self, flag, dataDir='./starter_set/', data_range=(0, 8), n_class=5, onehot=False):
        self.onehot = onehot
        assert(flag in ['train', 'eval', 'test', 'test_dev', 'kaggle'])
        print("load "+ flag+" dataset start")
        print("    from: %s" % dataDir)
        print("    range: [%d, %d)" % (data_range[0], data_range[1]))
        self.dataset = []
        for i in range(data_range[0], data_range[1]):
            img = Image.open(os.path.join(dataDir,flag,'eecs442_%04d.jpg' % i))

            pngreader = png.Reader(filename=os.path.join(dataDir,flag,'eecs442_%04d.png' % i))
            w,h,row,info = pngreader.read()
            label = np.array(list(row)).astype('uint8')

            # Normalize input image
            img = np.asarray(img).astype("f").transpose(2, 0, 1)/128.0-1.0
            # Convert to n_class-dimensional onehot matrix
            label_ = np.asarray(label)
            label = np.zeros((n_class, img.shape[1], img.shape[2])).astype("i")
            for j in range(n_class):
                label[j, :] = label_ == j
            self.dataset.append((img, label))
        print("load dataset done")

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, index):
        img, label = self.dataset[index]
        label = torch.FloatTensor(label)
        if not self.onehot:
            label = torch.argmax(label, dim=0)
        else:
            label = label.long()

        return torch.FloatTensor(img), torch.LongTensor(label)

import os
import time

import cv2
import matplotlib.pyplot as plt
import numpy as np
import png
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from colormap.colors import Color, hex2rgb
from sklearn.metrics import average_precision_score as ap_score
from torch.utils.data import DataLoader
from torchvision import datasets, models, transforms
from tqdm import tqdm

# from dataset import FacadeDataset

N_CLASS=5

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.n_class = N_CLASS
        self.layers = nn.Sequential(
            #########################################
            ###        TODO: Add more layers      ###
            nn.Conv2d(3, 64, 5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(128, 256, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            # nn.Conv2d(256, 128, 3, padding=1),
            # nn.ReLU(inplace=True),
            # nn.MaxPool2d(2, 2),

            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.ConvTranspose2d(64, 16, 4, stride=2, padding=1),
            nn.Conv2d(16, self.n_class, 1, padding=0)

            #########################################
            #nn.Conv2d(3, self.n_class, 1, padding=0)
            # nn.ReLU(inplace=True)
            )

    def forward(self, x):
        x = self.layers(x)
        return x


def save_label(label, path):
    '''
    Function for ploting labels.
    '''
    colormap = [
        '#000000',
        '#0080FF',
        '#80FF80',
        '#FF8000',
        '#FF0000',
    ]
    assert(np.max(label)<len(colormap))
    colors = [hex2rgb(color, normalise=False) for color in colormap]
    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)
    with open(path, 'wb') as f:
        w.write(f, label)

def train(trainloader, net, criterion, optimizer, device, epoch):
    '''
    Function for training.
    '''
    start = time.time()
    running_loss = 0.0
    net = net.train()

    losses = 0.
    cnt = 0
    for images, labels in tqdm(trainloader):
        images = images.to(device)
        labels = labels.to(device)
        optimizer.zero_grad()
        output = net(images)
        #print(output.detach().cpu().numpy().shape)
        loss = criterion(output, labels)
        loss.backward()
        optimizer.step()
        running_loss = loss.item()
        losses += running_loss
        cnt += 1
    end = time.time()
    print('[epoch %d] loss: %.3f average_losses: %.3f elapsed time %.3f' %
          (epoch, running_loss, losses / cnt, end-start))
    return losses / cnt

def test(testloader, net, criterion, device):
    '''
    Function for testing.
    '''
    losses = 0.
    cnt = 0
    with torch.no_grad():
        net = net.eval()
        for images, labels in tqdm(testloader):
            images = images.to(device)
            labels = labels.to(device)
            output = net(images)
            #print(output.detach().cpu().numpy().shape)
            loss = criterion(output, labels)
            losses += loss.item()
            cnt += 1
    print(losses / cnt)
    return (losses/cnt)


def cal_AP(testloader, net, criterion, device):
    '''
    Calculate Average Precision
    '''
    losses = 0.
    cnt = 0
    with torch.no_grad():
        net = net.eval()
        preds = [[] for _ in range(5)]
        heatmaps = [[] for _ in range(5)]
        for images, labels in tqdm(testloader):
            images = images.to(device)
            labels = labels.to(device)
            output = net(images).cpu().numpy()
            for c in range(5):
                preds[c].append(output[:, c].reshape(-1))
                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))

        aps = []
        for c in range(5):
            preds[c] = np.concatenate(preds[c])
            heatmaps[c] = np.concatenate(heatmaps[c])
            if heatmaps[c].max() == 0:
                ap = float('nan')
            else:
                ap = ap_score(heatmaps[c], preds[c])
                aps.append(ap)
            print("AP = {}".format(ap))
        average_ap = np.mean(aps)
        print("Average Ap = {}".format(average_ap))

    # print(losses / cnt)
    return None


def get_result(testloader, net, device, folder='output_train'):
    result = []
    cnt = 1
    with torch.no_grad():
        net = net.eval()
        cnt = 0
        for images, labels in tqdm(testloader):
            images = images.to(device)
            labels = labels.to(device)
            output = net(images)[0].cpu().numpy()
            c, h, w = output.shape
            assert(c == N_CLASS)
            y = np.zeros((h,w)).astype('uint8')
            for i in range(N_CLASS):
                mask = output[i]>0.5
                y[mask] = i
            gt = labels.cpu().data.numpy().squeeze(0).astype('uint8')
            save_label(y, './{}/y{}.png'.format(folder, cnt))
            save_label(gt, './{}/gt{}.png'.format(folder, cnt))
            plt.imsave(
                './{}/x{}.png'.format(folder, cnt),
                ((images[0].cpu().data.numpy()+1)*128).astype(np.uint8).transpose(1,2,0))

            cnt += 1
            
colors = [[31, 120, 180], [51, 160, 44]]
colors = [(r / 255, g / 255, b / 255) for (r, g, b) in colors]
 
def plot_losses(train_history, val_history):
    x = np.arange(1, len(train_history) + 1)

    plt.figure(figsize=(8, 6))
    plt.plot(x, train_history, color=colors[0], label="Training loss", linewidth=2)
    plt.plot(x, val_history, color=colors[1], label="Validation loss", linewidth=2)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(loc='upper right')
    plt.title("Evolution of the training and validation loss")
    plt.show()

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print('device: ', device)
# TODO change data_range to include all train/evaluation/test data.
# TODO adjust batch_size.
train_data = FacadeDataset(flag='train', data_range=(0, 768), onehot=False)
print(train_data.__len__())
train_loader = DataLoader(train_data, batch_size=16)

val_data = FacadeDataset(flag='train', data_range=(768,896), onehot=False)
print(val_data.__len__())
val_loader = DataLoader(train_data, batch_size=32)

test_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=False)
test_loader = DataLoader(test_data, batch_size=1)
ap_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=True)
ap_loader = DataLoader(ap_data, batch_size=1)

lr = 1e-3
name = '6layerfcn_lr1e-3'
net = Net().to(device)
criterion = nn.CrossEntropyLoss() #TODO decide loss
optimizer = torch.optim.Adam(net.parameters(), lr, weight_decay=1e-3)

print('\nStart training')
train_history = []
val_history = []
for epoch in range(40): #TODO decide epochs
    print('-----------------Epoch = %d-----------------' % (epoch+1))
    trainloss = train(train_loader, net, criterion, optimizer, device, epoch+1)
    # TODO create your evaluation set, load the evaluation set and test on evaluation set
    val_loss = test(val_loader, net, criterion, device)

    train_history.append(trainloss)
    val_history.append(val_loss)

plot_losses(train_history, val_history)

lr = 5e-4
name = '6layerfcn_lr1e-3'

print('\nStart training')
train_history1 = []
val_history1 = []
for epoch in range(20): #TODO decide epochs
    print('-----------------Epoch = %d-----------------' % (epoch+1))
    trainloss = train(train_loader, net, criterion, optimizer, device, epoch+1)
    # TODO create your evaluation set, load the evaluation set and test on evaluation set
    val_loss = test(val_loader, net, criterion, device)

    train_history1.append(trainloss)
    val_history1.append(val_loss)

train_history.extend(train_history1)
val_history.extend(val_history1)
plot_losses(train_history, val_history)

torch.save(net.state_dict(), './models/model_{}80.pth'.format(name))

print('\nFinished Training, Testing on test set')
test(test_loader, net, criterion, device)
print('\nGenerating Unlabeled Result')
result = get_result(test_loader, net, device, folder='output_test')

cal_AP(ap_loader, net, criterion, device)

import matplotlib.pyplot as plt

im = plt.imread('my_facade.jpg')
im = (im-127.5) / 127.5
trans = transforms.ToTensor()
im = trans(im).float().to(device)
im = im.view(1, 3, 256, 256)
output = net(im)[0].detach().cpu().numpy()
c, h, w = output.shape
assert(c == N_CLASS)
y = np.zeros((h,w)).astype('uint8')
for i in range(N_CLASS):
    mask = output[i]>0.5
    y[mask] = i
save_label(y, './my_facade_labels.png')

!zip -r output_test.zip ./output_test

from google.colab import files
files.download('./output_test.zip')
files.download('./models/model_starter_net.pth')