{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proj 2 Augmented Reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(im, num_pts=None):\n",
    "    print('Please select points on image.')\n",
    "    plt.imshow(im)\n",
    "    pts = np.array(plt.ginput(num_pts if num_pts else 100, timeout=0, mouse_pop=None, mouse_stop=3))\n",
    "    plt.close()\n",
    "    pts = np.roll(pts, shift=1, axis=1)\n",
    "    return pts\n",
    "\n",
    "def draw(img, imgpts):\n",
    "#     imgpts = np.int32(imgpts).reshape(-1,2)\n",
    "\n",
    "    # draw ground floor in green\n",
    "    img = cv2.drawContours(img, [imgpts[:4]],-1,(0,255,0),-3)\n",
    "    # draw pillars in blue color\n",
    "    for i,j in zip(range(4),range(4,8)):\n",
    "        img = cv2.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)\n",
    "    # draw top layer in red color\n",
    "    img = cv2.drawContours(img, [imgpts[4:]],-1,(0,0,255),3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read fist frame of the video and choose Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fist frame of the video and choose Region of Interest\n",
    "%matplotlib qt\n",
    "video = cv2.VideoCapture(\"cube2.mov\")\n",
    "# the channel order is in BGR\n",
    "ok, init_frame = video.read()\n",
    "pts = get_points(init_frame, num_pts=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tracked ROI in every frame \n",
    "%matplotlib inline\n",
    "num_ROI = pts.shape[0]\n",
    "video = cv2.VideoCapture(\"cube2.mov\")\n",
    "# the channel order is in BGR\n",
    "ok, frame = video.read()\n",
    "height, width, channels = frame.shape\n",
    "\n",
    "bboxes = [(pt[1]-9, pt[0]-9, 17, 17) for pt in pts]\n",
    "\n",
    "# trackers = [cv2.TrackerGOTURN_create() for i in range(num_ROI)]\n",
    "trackers = [cv2.TrackerMedianFlow_create() for i in range(num_ROI)]\n",
    "oks = [tracker.init(frame, bbox) for tracker, bbox in zip(trackers, bboxes)]\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "videowriter = cv2.VideoWriter('test.mp4',fourcc, 60, (width,height))\n",
    "\n",
    "im_coords_all = []\n",
    "idxes_all = []\n",
    "while ok:\n",
    "    im_coords = []\n",
    "    idxes = []\n",
    "    cnt = 0\n",
    "    for ok, bbox in zip(oks, bboxes):\n",
    "        if ok:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0,255,0), 2, 1)\n",
    "            center = (np.array(p1) + np.array(p2)) // 2\n",
    "            im_coords.append(center)\n",
    "            idxes.append(cnt)\n",
    "        cnt += 1\n",
    "    assert len(idxes) == len(im_coords)\n",
    "    im_coords_all.append(im_coords)\n",
    "    idxes_all.append(idxes)\n",
    "#     cv2.imshow(\"Tracking\", frame)\n",
    "#     videowriter.write(frame)\n",
    "    # Exit if ESC pressed\n",
    "#     k = cv2.waitKey(1) & 0xff\n",
    "#     if k == 27 : break\n",
    "    ok, frame = video.read()\n",
    "    oks_bboxes = [tracker.update(frame) for tracker in trackers]\n",
    "    oks = [ok_bbox[0] for ok_bbox in oks_bboxes]\n",
    "    bboxes = [ok_bbox[1] for ok_bbox in oks_bboxes]\n",
    "videowriter.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corresponding 3-D coordinates\n",
    "world_coords = np.array([[0, 0, 4], [0, 1.5, 4], [0, 3, 4], [0, 4.5, 4], [0, 6, 4],\n",
    "                        [1.5, 6, 4], [1.5, 4.5, 4], [1.5, 3, 4], [1.5, 1.5, 4], [1.5, 0, 4],\n",
    "                        [3.5, 0, 4], [3.5, 1.5, 4], [3.5, 3, 4], [3.5, 4.5, 4], [3.5, 6, 4],\n",
    "                        [5, 6, 4], [5, 4.5, 4], [5, 3, 4], [5, 1.5, 4], [5, 0, 4],\n",
    "                        [5, 0, 2], [5, 1.5, 2], [5, 3, 2], [5, 4.5, 2], [5, 6, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get projection matrix M for every frame\n",
    "m_list = []\n",
    "for idxes, im_coords in tqdm(zip(idxes_all, im_coords_all)):\n",
    "    # do least square for every frame\n",
    "    b = np.array([[im_coord[0], im_coord[1], 1] for im_coord in im_coords]).flatten()\n",
    "    A_list = []\n",
    "    for idx in idxes:\n",
    "        A_temp = np.concatenate([world_coords[idx], [1], np.zeros(8)])\n",
    "        A_temp = np.vstack([A_temp, np.roll(A_temp, 4), np.roll(A_temp, 8)])\n",
    "        A_list.append(A_temp)\n",
    "#     print(len(A_list))\n",
    "    A = np.vstack(A_list)\n",
    "#     print(A.shape, b.shape)\n",
    "#     break\n",
    "    m = np.linalg.lstsq(A, b)[0].reshape(3, 4)\n",
    "    m_list.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project 3-D coordinates to each frame using projection matrix M \n",
    "# and see if they deviate from tracked points too much\n",
    "video = cv2.VideoCapture(\"cube2.mov\")\n",
    "# the channel order is in BGR\n",
    "ok, frame = video.read()\n",
    "m0 = m_list[0]\n",
    "for m, idxes in zip(m_list, idxes_all):\n",
    "    for idx in idxes:\n",
    "        coord = world_coords[idx]\n",
    "        im_xy = m @ np.concatenate([coord, [1]]) \n",
    "        cv2.circle(frame, (int(im_xy[0]),int(im_xy[1])), radius=5, color=(0,255,0), thickness=-1)\n",
    "    cv2.imshow(\"recovered\", frame)\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27 : break\n",
    "    ok, frame = video.read()\n",
    "    \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project a cube into each frame of the original video\n",
    "axis = np.float32([[1.5, 1.5, 4], [1.5, 4.5 ,4], [3.5, 4.5 ,4], [3.5, 1.5, 4],\n",
    "                   [1.5, 1.5, 6], [1.5, 4.5, 6], [3.5, 4.5, 6], [3.5, 1.5, 6]])\n",
    "video = cv2.VideoCapture(\"cube2.mov\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "videowriter = cv2.VideoWriter('result.mp4',fourcc, 60, (width,height))\n",
    "# the channel order is in BGR\n",
    "ok, frame = video.read()\n",
    "m0 = m_list[0]\n",
    "for m, idxes in zip(m_list, idxes_all):\n",
    "    axis_xy = []\n",
    "    for pt_xyz in axis:\n",
    "        pt_xy = m @ np.concatenate([pt_xyz, [1]])\n",
    "        axis_xy.append(pt_xy[0:2])\n",
    "    axis_xy = np.asarray(axis_xy)\n",
    "    frame = draw(frame, axis_xy)\n",
    "    cv2.imshow(\"recovered\", frame)\n",
    "    videowriter.write(frame)\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27 : break\n",
    "    ok, frame = video.read()\n",
    "video.release()\n",
    "videowriter.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs194",
   "language": "python",
   "name": "cs194"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
